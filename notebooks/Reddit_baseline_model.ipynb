{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c261d74e-2340-4a45-9702-1051ee43f0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Install necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mlflow\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split,cross_val_predict,StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0b64a113-0afb-4124-9d4b-83036170f524",
   "metadata": {},
   "source": [
    "#1.## check the mlflow server---Testing\n",
    "mlflow.set_tracking_uri(\"http://ec2-13-62-127-52.eu-north-1.compute.amazonaws.com:5000/\")\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_param(\"param1\", 15)\n",
    "    mlflow.log_metric(\"metric1\", 0.89)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e975c6f3-57eb-4805-bdd0-58081c4ce1ba",
   "metadata": {},
   "source": [
    "# run the base line model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f40fe763-8267-4c9e-8bb1-a36506522bf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_comment</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>family mormon have never tried explain them t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>buddhism has very much lot compatible with chr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>seriously don say thing first all they won get...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what you have learned yours and only yours wha...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>for your own benefit you may want read living ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       clean_comment  category\n",
       "0   family mormon have never tried explain them t...         1\n",
       "1  buddhism has very much lot compatible with chr...         1\n",
       "2  seriously don say thing first all they won get...        -1\n",
       "3  what you have learned yours and only yours wha...         0\n",
       "4  for your own benefit you may want read living ...         1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/Himanshu-1703/reddit-sentiment-analysis/refs/heads/main/data/reddit.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "404f9eed-e8b7-45c4-b7b2-78b760fd13d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66c905c9-31ae-4689-99b3-7de9448d309a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5a35f57-56f4-49ea-9296-6bd3d8e27896",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~(df['clean_comment'].str.strip() == '')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5506254-d511-4819-bea7-118751a55311",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\mukti\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\mukti\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ensure necessary nltk data is downloaded\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1af04917-3f86-4b4a-919a-165a891fd21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the preprocessing function\n",
    "\n",
    "def preprocess_comment(comment):\n",
    "    # convert to lower case\n",
    "    comment = comment.lower()\n",
    "\n",
    "    #remove the trailing and leading space\n",
    "    comment = comment.strip()\n",
    "\n",
    "    #remove the newline characters\n",
    "    comment = re.sub('\\n',' ',comment)\n",
    "\n",
    "    #remove the non-alphanumeric character, except punctuations\n",
    "    comment = re.sub(r'[^A-Za-z0-9\\s!?.,]', '', comment)\n",
    "\n",
    "    #remove the stopwords but retain the important ones for sentiment analysis\n",
    "    stop_words = set(stopwords.words('english')) -{'not','but','however','no','yet'}\n",
    "    comment = ' '.join([word for word in comment.split() if word.lower() not in stop_words])\n",
    "\n",
    "    #lemmatize the words\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    comment = ' '.join([lemmatizer.lemmatize(word) for word in comment.split()])\n",
    "\n",
    "    return comment\n",
    "    \n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6047b572-734b-45a0-ad19-690e071b89d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply the preprocessing function to clean clean_comment\n",
    "df['clean_comment']= df['clean_comment'].apply(preprocess_comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "48e65c17-7136-40e4-8391-a8f884a8487b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_comment</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>family mormon never tried explain still stare ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>buddhism much lot compatible christianity espe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>seriously say thing first get complex explain ...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>learned want teach different focus goal not wr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>benefit may want read living buddha living chr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       clean_comment  category\n",
       "0  family mormon never tried explain still stare ...         1\n",
       "1  buddhism much lot compatible christianity espe...         1\n",
       "2  seriously say thing first get complex explain ...        -1\n",
       "3  learned want teach different focus goal not wr...         0\n",
       "4  benefit may want read living buddha living chr...         1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bab9f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv('reddit_preprocessing.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a055d0de-8f41-4bed-81ca-b8074131b5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## apply BOW\n",
    "vectorizer = CountVectorizer(max_features=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094d1671-3192-4b98-b1a3-fc07d2ab791c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = vectorizer.fit_transform(df['clean_comment']).toarray()\n",
    "y = df['category'] # Assuming 'sentiment' is the target variable (0 or 1 for binary classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf223af-2f59-46ba-93c4-aafbfce061e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70521c16-b371-4f58-be45-11c0abf961a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3148c429-efce-490f-99ad-b8e2bf784d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 2 : Set up the mlflow tracking server \n",
    "mlflow.set_tracking_uri(\"http://ec2-51-21-223-34.eu-north-1.compute.amazonaws.com:5000/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e210ede3-ad08-431d-bcfa-4e13212126e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_experiment(\"RF Baseline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471fdb75-0e34-4b7a-80cb-e98222ce5fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# design the base line model\n",
    "#step 1: split the data into traing and testing sets(80% train, 20% test)\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=42,stratify=y) #stratify=y for imbalanced dataset\n",
    "\n",
    "#step 2: Define and train a Random Forest baseline model using a  simpke test train split\n",
    "\n",
    "with mlflow.start_run() as run:\n",
    "    #log the description of the run\n",
    "    mlflow.set_tag(\"mlflow.runName\", \"Randomforest_baseline_TrainTestSplit\")\n",
    "    mlflow.set_tag(\"experiment_type\", \"Baseline\")\n",
    "    mlflow.set_tag(\"model_type\",\"RandomForestClassifier\")\n",
    "\n",
    "    # Add a description\n",
    "    mlflow.set_tag(\"description\", \"Baseline RandomForest model for sentiment analysis using Bag of Words (BoW) with a simple train-test split\")\n",
    "\n",
    "    #log parameters for the vectorizers\n",
    "    mlflow.log_param(\"vectorizer_type\", \"CountVectorizer\")\n",
    "    mlflow.log_param(\"vactorizer_max_features\",vectorizer.max_features)\n",
    "\n",
    "    #log Random Forest Classifier\n",
    "    n_estimators = 150\n",
    "    max_depth = 15\n",
    "\n",
    "    mlflow.log_param(\"n_estimators\",n_estimators)\n",
    "    mlflow.log_param(\"max_depth\",max_depth)\n",
    "\n",
    "    #initialize and train the model\n",
    "    model = RandomForestClassifier(n_estimators=n_estimators,max_depth=max_depth,random_state=42)\n",
    "    model.fit(X_train,y_train)\n",
    "\n",
    "    # make the prediction\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # log metrics \n",
    "    accuracy = accuracy_score(y_test,y_pred)\n",
    "    mlflow.log_metric(\"accuracy\",accuracy)\n",
    "\n",
    "    # classification report for each metric and log in mlflow\n",
    "\n",
    "    classification_rep = classification_report(y_test,y_pred,output_dict=True)\n",
    "\n",
    "    for label,metrics in classification_rep.items():\n",
    "        if isinstance(metrics,dict):\n",
    "            for metrics,value in metrics.item():   ###for precisison ,recall ,f1 score etc\n",
    "                mlflow.log_metric(f\"{label}_{metrics}\",value)\n",
    "\n",
    "    # confusion metrics plot\n",
    "    conf_matrix = confusion_matrix(y_test,y_pred)\n",
    "    plt.figure(figsize=(8,6))\n",
    "    sns.heatmap(conf_matrix,annot=True, fmt=\"d\",cmap=\"Blues\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"Actual\")\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "\n",
    "    #save and log the confusion matrix plot\n",
    "    plt.savefig('confusion_matrix/confusion_matrix.png')\n",
    "    mlflow.log_artifact('confusion_matrix/confusion_matrix.png')\n",
    "\n",
    "    #log the model\n",
    "    mlflow.sklearn.log_model(model,\"random_forest_model\")\n",
    "\n",
    "    # Optionally log the dataset itself (if it's small enough)\n",
    "    df.to_csv(\"dataset.csv\", index=False)\n",
    "    mlflow.log_artifact(\"dataset.csv\")\n",
    "\n",
    "# Display final accuracy\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a492b347-7a33-49a8-b9ba-c07c5eef9596",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216e0492-d312-446e-87bc-c737e0fb4dd1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
